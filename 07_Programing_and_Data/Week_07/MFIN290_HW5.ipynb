{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 (Woosoo Kim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Yahoo! Finance - Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Scraping Project\n",
    "\n",
    "It's time to apply your newly-acquired web-scraping skills to obtain earnings and pricing data from *Yahoo! Finance*.\n",
    "\n",
    "#### Data from Yahoo! Finance\n",
    "\n",
    "*Yahoo! Finance* maintains data on firms' reported earnings per share (EPS), analysts' consensus estimate of EPS, and the date that firms' announce EPS. \n",
    "\n",
    "# Instructions\n",
    "\n",
    "#### Import Modules and Create Directories\n",
    "\n",
    "1. Import the following modules:\n",
    "    1. pandas as pd\n",
    "    2. webdriver from selenium\n",
    "    3. from selenium.webdriver.common.by import By\n",
    "    4. os\n",
    "    5. shutil\n",
    "    6. datetime as dt\n",
    "    7. time\n",
    "    8. requests\n",
    "2. Create a variable called `fromdirectory` with the directory location of your Downloads folder.\n",
    "3. Create a variable called `todirectory` with the directory of a new folder called 'Yahoo Finance Data' contained within the folder containing this Jupyter Notebook. Use the **os.getcwd** function to get the current working directory (i.e., the directory of the folder containing this Jupyter Notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution - Import Modules and Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "import shutil\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "# Ignore warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"Passing literal html to 'read_html' is deprecated.*\")\n",
    "\n",
    "# Where you save files (create a new folder called \"Yahoo Finance Data\")\n",
    "todirectory = os.getcwd()+'/Yahoo Finance Data/' \n",
    "if not os.path.exists(todirectory):\n",
    "    os.mkdir(todirectory)\n",
    "\n",
    "# My Downloads direc\n",
    "fromdirectory = '/Users/ws/Downloads/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Function to Extract the Earnings Per Share Data\n",
    "\n",
    "Create a function called `get_earnings` to obtain the EPS data found on *Yahoo! Finance* at https://finance.yahoo.com/calendar/earnings?&symbol=TICKER.\n",
    "\n",
    "1. Include `ticker` as an input to the `get_earnings` function.\n",
    "2. Use the **read_html** function from the **pandas** module to read in the Yahoo! Finance URL into a list called `dfs`. Use the option `na_values = '-'` in the **read_html** function because the missing values are coded as `'-'` in the earnings table on Yahoo Finance.\n",
    "3. Create a variable called `earnings` equal to the DataFrame in the `dfs` list containing the earnings table.\n",
    "4. Remove rows from the `earnings` DataFrame in which the `Surprise(%)` is missing using the **.notna()** function.\n",
    "5. Convert the `Earnings Date` column in the `earnings` DataFrame to a *datetime* object called `earnings_date`. See HINT below.\n",
    "6. Keep the following columns in the `earnings` DataFrame: 'Symbol','earnings_date','EPS Estimate','Reported EPS', and 'Surprise(%)'.\n",
    "7. Use the **to_csv** function from the **pandas** module to export the `earnings` DataFrame to a file called 'TICKER_earnings.csv' (e.g., 'AAPL_earnings.csv) in a new folder called 'Yahoo Finance Data'. Use the `index=False` option.\n",
    "8. Test the `get_earnings` function by passing it the ticker 'F'. Is the correct earnings table saved to a file called 'F_earnings.csv' in the 'Yahoo Finance Data' folder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution - Create a Function to Extract the Earnings Per Share Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F_earnings.csv', '.DS_Store']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See HINT Below\n",
    "def convert_date(date):\n",
    "    fixed_date = date.split(',')\n",
    "    fixed_date = fixed_date[0]+','+fixed_date[1]\n",
    "    fixed_date = dt.datetime.strptime(fixed_date, '%b %d, %Y')\n",
    "    return fixed_date\n",
    "\n",
    "def get_earnings(ticker):\n",
    "    \n",
    "    # Set up headless Chrome options\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # Optional: runs the browser in the background\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # Load the Yahoo Finance Profile page\n",
    "    url = 'https://finance.yahoo.com/calendar/earnings?&symbol='+ticker\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    driver.implicitly_wait(2)  # Waits up to 2 seconds \n",
    "\n",
    "    # Retrieve HTML\n",
    "    html = driver.page_source\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    # 2. Read tables\n",
    "    dfs = pd.read_html(html, na_values = '-')\n",
    "    \n",
    "    # 3. Create a variable called earnings\n",
    "    earnings = dfs[0].copy()\n",
    "\n",
    "    # 4. Remove rows where Surprise(%) is missing\n",
    "    earnings = earnings[earnings['Surprise(%)'].notna()]\n",
    "\n",
    "    # 5. Convert Earnings Date to a datetime object\n",
    "    earnings['earnings_date'] = earnings['Earnings Date'].apply(convert_date)\n",
    "\n",
    "    # 6. Keep only the Symbol, earnings_date, EPS Estimate, Reported EPS, and Surprise(%) columns\n",
    "    earnings = earnings[['Symbol','earnings_date','EPS Estimate','Reported EPS','Surprise(%)']]\n",
    "    \n",
    "    # 7. Save the earnings Data to a CSV file\n",
    "    earnings.to_csv(todirectory+ticker+'_earnings.csv', index=False)\n",
    "\n",
    "# 8. Test get_earnings()\n",
    "get_earnings('F')\n",
    "os.listdir(todirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HINT for # 5:\n",
    "\n",
    "The `Earnings Date` column is stored in the `earnings` DataFrame as a string object. You can use text splitting and the **datetime** function on that string to extract the date. To explain how to do this, let's start with a simple Python example.\n",
    "\n",
    "Suppose you have a string variable called `date`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = 'Oct 23, 2019, 4 AMEST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the date and store the variable as a **datetime** object, we can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "fixed_date = date.split(',')\n",
    "fixed_date = fixed_date[0]+','+fixed_date[1]\n",
    "fixed_date = dt.datetime.strptime(fixed_date, '%b %d, %Y')\n",
    "print(fixed_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the same type of analysis for a column in a pandas DataFrame, you can create a function that takes the `date` as in input and returns the newly-created **datetime** `date`. You can then apply that function to the appropriate column in the **pandas** DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date):\n",
    "    fixed_date = date.split(',')\n",
    "    fixed_date = fixed_date[0]+','+fixed_date[1]\n",
    "    fixed_date = dt.datetime.strptime(fixed_date, '%b %d, %Y')\n",
    "    return fixed_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>Earnings Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>Oct 23, 2019, 4 AMEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Dec 5, 2017, 6 AMEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WMT</td>\n",
       "      <td>Jan 20, 2019, 9 PMEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker          Earnings Date\n",
       "0      F  Oct 23, 2019, 4 AMEST\n",
       "1   AAPL   Dec 5, 2017, 6 AMEST\n",
       "2    WMT  Jan 20, 2019, 9 PMEST"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings = pd.DataFrame({'ticker':['F', 'AAPL', 'WMT'], 'Earnings Date':['Oct 23, 2019, 4 AMEST', 'Dec 5, 2017, 6 AMEST', 'Jan 20, 2019, 9 PMEST']})\n",
    "earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>Earnings Date</th>\n",
       "      <th>earnings_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>Oct 23, 2019, 4 AMEST</td>\n",
       "      <td>2019-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Dec 5, 2017, 6 AMEST</td>\n",
       "      <td>2017-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WMT</td>\n",
       "      <td>Jan 20, 2019, 9 PMEST</td>\n",
       "      <td>2019-01-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker          Earnings Date earnings_date\n",
       "0      F  Oct 23, 2019, 4 AMEST    2019-10-23\n",
       "1   AAPL   Dec 5, 2017, 6 AMEST    2017-12-05\n",
       "2    WMT  Jan 20, 2019, 9 PMEST    2019-01-20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings['earnings_date'] = earnings['Earnings Date'].apply(convert_date)\n",
    "earnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain S&P 500 Tickers from Wikipedia\n",
    "\n",
    "1. Use the **pandas read_html** function to read in this list of S&P 500 companies from Wikipedia: https://en.wikipedia.org/wiki/List_of_S%26P_500_companies.\n",
    "2. Create a DataFrame called `sp500`, keeping only the `Symbol` and `Security` columns.\n",
    "3. Keep only the first 10 rows in the `sp500` DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution - Obtain S&P 500 Tickers from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>91142</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADBE</td>\n",
       "      <td>Adobe Inc.</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Application Software</td>\n",
       "      <td>San Jose, California</td>\n",
       "      <td>1997-05-05</td>\n",
       "      <td>796343</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMD</td>\n",
       "      <td>Advanced Micro Devices</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Semiconductors</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>2488</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AES</td>\n",
       "      <td>AES Corporation</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Independent Power Producers &amp; Energy Traders</td>\n",
       "      <td>Arlington, Virginia</td>\n",
       "      <td>1998-10-02</td>\n",
       "      <td>874761</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AFL</td>\n",
       "      <td>Aflac</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Life &amp; Health Insurance</td>\n",
       "      <td>Columbus, Georgia</td>\n",
       "      <td>1999-05-28</td>\n",
       "      <td>4977</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Life Sciences Tools &amp; Services</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "      <td>2000-06-05</td>\n",
       "      <td>1090872</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                Security             GICS Sector  \\\n",
       "0    MMM                      3M             Industrials   \n",
       "1    AOS             A. O. Smith             Industrials   \n",
       "2    ABT     Abbott Laboratories             Health Care   \n",
       "3   ABBV                  AbbVie             Health Care   \n",
       "4    ACN               Accenture  Information Technology   \n",
       "5   ADBE              Adobe Inc.  Information Technology   \n",
       "6    AMD  Advanced Micro Devices  Information Technology   \n",
       "7    AES         AES Corporation               Utilities   \n",
       "8    AFL                   Aflac              Financials   \n",
       "9      A    Agilent Technologies             Health Care   \n",
       "\n",
       "                              GICS Sub-Industry    Headquarters Location  \\\n",
       "0                      Industrial Conglomerates    Saint Paul, Minnesota   \n",
       "1                             Building Products     Milwaukee, Wisconsin   \n",
       "2                         Health Care Equipment  North Chicago, Illinois   \n",
       "3                                 Biotechnology  North Chicago, Illinois   \n",
       "4                IT Consulting & Other Services          Dublin, Ireland   \n",
       "5                          Application Software     San Jose, California   \n",
       "6                                Semiconductors  Santa Clara, California   \n",
       "7  Independent Power Producers & Energy Traders      Arlington, Virginia   \n",
       "8                       Life & Health Insurance        Columbus, Georgia   \n",
       "9                Life Sciences Tools & Services  Santa Clara, California   \n",
       "\n",
       "   Date added      CIK      Founded  \n",
       "0  1957-03-04    66740         1902  \n",
       "1  2017-07-26    91142         1916  \n",
       "2  1957-03-04     1800         1888  \n",
       "3  2012-12-31  1551152  2013 (1888)  \n",
       "4  2011-07-06  1467373         1989  \n",
       "5  1997-05-05   796343         1982  \n",
       "6  2017-03-20     2488         1969  \n",
       "7  1998-10-02   874761         1981  \n",
       "8  1999-05-28     4977         1955  \n",
       "9  2000-06-05  1090872         1999  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Read HTML\n",
    "html = requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies').text\n",
    "dfs = pd.read_html(html)\n",
    "df = dfs[0]\n",
    "\n",
    "# 2. Create a DataFrame called sp500\n",
    "sp500 = df.copy()\n",
    "\n",
    "# 3. Keep only the first 10 rows\n",
    "sp500 = sp500.head(10)\n",
    "\n",
    "# Print the first 10 rows\n",
    "sp500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through the First Ten Firms in the S&P 500 DataFrame to Obtain the Earnings and Price Tables for Each Ticker Symbol\n",
    "\n",
    "1. Use a **for** loop to loop through each row of the `sp500` DataFrame using the **iterrows** function. See the HINT below.\n",
    "2. For each `Symbol` (i.e., ticker), download the 'TICKER_earnings.csv' file to the \"Yahoo Finance Data\" folder using the `get_earnings` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution - Loop through the First Ten Firms in the S&P 500 DataFrame to Obtain the Earnings and Price Tables for Each Ticker Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in sp500.iterrows():\n",
    "    ticker = row['Symbol']\n",
    "    get_earnings(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HINT for # 2\n",
    "\n",
    "To loop through each row of a DataFrame called `sp500` and to extract the `Symbol` (i.e., ticker) from each row, you can use the following code:\n",
    "\n",
    "    for index,row in sp500.iterrows():\n",
    "        ticker = row['Symbol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Earnings Data\n",
    "\n",
    "1. Create an empty list called `all_data`. (i.e., `all_data = []`)\n",
    "2. Create a list of file names called `filenames` from the Yahoo Finance Data folder using `os.listdir(DIRECTORY)`.\n",
    "3. Use a **for** loop to loop through each file name in the `filenames` list and do the following:\n",
    "    1. If '_earnings' is in the filename, execute the next steps.\n",
    "    2. Extract the ticker from the filename using the **.split()** function.\n",
    "    3. Read the file into a **pandas** DataFrame called `data` using the **read_csv** function.\n",
    "    4. Add the ticker you extracted in Step B above to a new column called `ticker` in the `data` DataFrame.\n",
    "    5. Append the `data` DataFrame to the `all_data` list you created in Step 1 above using the **.append()** function.\n",
    "4. Create a DataFrame called `earnings` by concatenating the `all_data` list of DataFrames using the code: `earnings = pd.concat(all_data)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution - Combine Earnings Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>earnings_date</th>\n",
       "      <th>EPS Estimate</th>\n",
       "      <th>Reported EPS</th>\n",
       "      <th>Surprise(%)</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2024-08-21</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>5.01</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.34</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2024-02-27</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.29</td>\n",
       "      <td>5.45</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.38</td>\n",
       "      <td>2.86</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2023-08-15</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.43</td>\n",
       "      <td>4.80</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol earnings_date  EPS Estimate  Reported EPS  Surprise(%) ticker\n",
       "0      A    2024-08-21          1.26          1.32         5.01      A\n",
       "1      A    2024-05-29          1.19          1.22         2.34      A\n",
       "2      A    2024-02-27          1.22          1.29         5.45      A\n",
       "3      A    2023-11-20          1.34          1.38         2.86      A\n",
       "4      A    2023-08-15          1.36          1.43         4.80      A"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create an empty list\n",
    "all_data = []\n",
    "\n",
    "# 2. Create a list\n",
    "filenames = os.listdir(todirectory)\n",
    "\n",
    "# 3. Loop\n",
    "for filename in filenames:\n",
    "    # A. Conditional Flow\n",
    "    if '_earnings' in filename:\n",
    "        \n",
    "        # B. Extract Ticker\n",
    "        ticker = filename.split('_')[0]\n",
    "        \n",
    "        # C. Read the file\n",
    "        data = pd.read_csv(todirectory+filename)\n",
    "        \n",
    "        # D. Add the ticker\n",
    "        data['ticker'] = ticker\n",
    "        \n",
    "        # Append\n",
    "        all_data.append(data)\n",
    "\n",
    "# Create a Dataframe and print its head\n",
    "earnings = pd.concat(all_data)\n",
    "earnings.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
