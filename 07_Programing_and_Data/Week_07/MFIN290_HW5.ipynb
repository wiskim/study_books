{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 (Woosoo Kim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Yahoo! Finance - Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Scraping Project\n",
    "\n",
    "It's time to apply your newly-acquired web-scraping skills to obtain earnings and pricing data from *Yahoo! Finance*.\n",
    "\n",
    "#### Data from Yahoo! Finance\n",
    "\n",
    "*Yahoo! Finance* maintains data on firms' reported earnings per share (EPS), analysts' consensus estimate of EPS, and the date that firms' announce EPS. \n",
    "\n",
    "# Instructions\n",
    "\n",
    "#### Import Modules and Create Directories\n",
    "\n",
    "1. Import the following modules:\n",
    "    1. pandas as pd\n",
    "    2. webdriver from selenium\n",
    "    3. from selenium.webdriver.common.by import By\n",
    "    4. os\n",
    "    5. shutil\n",
    "    6. datetime as dt\n",
    "    7. time\n",
    "    8. requests\n",
    "2. Create a variable called `fromdirectory` with the directory location of your Downloads folder.\n",
    "3. Create a variable called `todirectory` with the directory of a new folder called 'Yahoo Finance Data' contained within the folder containing this Jupyter Notebook. Use the **os.getcwd** function to get the current working directory (i.e., the directory of the folder containing this Jupyter Notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution - Import Modules and Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "import shutil\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "# Ignore warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"Passing literal html to 'read_html' is deprecated.*\")\n",
    "\n",
    "# Where you save files (create a new folder called \"Yahoo Finance Data\")\n",
    "todirectory = os.getcwd()+'/Yahoo Finance Data/' \n",
    "if not os.path.exists(todirectory):\n",
    "    os.mkdir(todirectory)\n",
    "\n",
    "# My Downloads directory\n",
    "fromdirectory = '/Users/ws/Downloads/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Function to Extract the Earnings Per Share Data\n",
    "\n",
    "Create a function called `get_earnings` to obtain the EPS data found on *Yahoo! Finance* at https://finance.yahoo.com/calendar/earnings?&symbol=TICKER.\n",
    "\n",
    "1. Include `ticker` as an input to the `get_earnings` function.\n",
    "2. Use the **read_html** function from the **pandas** module to read in the Yahoo! Finance URL into a list called `dfs`. Use the option `na_values = '-'` in the **read_html** function because the missing values are coded as `'-'` in the earnings table on Yahoo Finance.\n",
    "3. Create a variable called `earnings` equal to the DataFrame in the `dfs` list containing the earnings table.\n",
    "4. Remove rows from the `earnings` DataFrame in which the `Surprise(%)` is missing using the **.notna()** function.\n",
    "5. Convert the `Earnings Date` column in the `earnings` DataFrame to a *datetime* object called `earnings_date`. See HINT below.\n",
    "6. Keep the following columns in the `earnings` DataFrame: 'Symbol','earnings_date','EPS Estimate','Reported EPS', and 'Surprise(%)'.\n",
    "7. Use the **to_csv** function from the **pandas** module to export the `earnings` DataFrame to a file called 'TICKER_earnings.csv' (e.g., 'AAPL_earnings.csv) in a new folder called 'Yahoo Finance Data'. Use the `index=False` option.\n",
    "8. Test the `get_earnings` function by passing it the ticker 'F'. Is the correct earnings table saved to a file called 'F_earnings.csv' in the 'Yahoo Finance Data' folder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution - Create a Function to Extract the Earnings Per Share Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See HINT Below\n",
    "def convert_date(date):\n",
    "    fixed_date = date.split(',')\n",
    "    fixed_date = fixed_date[0]+','+fixed_date[1]\n",
    "    fixed_date = dt.datetime.strptime(fixed_date, '%b %d, %Y')\n",
    "    return fixed_date\n",
    "\n",
    "def get_earnings(ticker):\n",
    "    \n",
    "    # Set up headless Chrome options\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # Optional: runs the browser in the background\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # Load the Yahoo Finance Profile page\n",
    "    url = 'https://finance.yahoo.com/calendar/earnings?&symbol='+ticker\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    driver.implicitly_wait(2)  # Waits up to 2 seconds \n",
    "\n",
    "    # Retrieve HTML\n",
    "    html = driver.page_source\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    # 2. Read tables\n",
    "    dfs = pd.read_html(html, na_values = '-')\n",
    "    \n",
    "    # 3. Create a variable called earnings\n",
    "    earnings = dfs[0].copy()\n",
    "\n",
    "    # 4. Remove rows where Surprise(%) is missing\n",
    "    earnings = earnings[earnings['Surprise(%)'].notna()]\n",
    "\n",
    "    # 5. Convert Earnings Date to a datetime object\n",
    "    earnings['earnings_date'] = earnings['Earnings Date'].apply(convert_date)\n",
    "\n",
    "    # 6. Keep only the Symbol, earnings_date, EPS Estimate, Reported EPS, and Surprise(%) columns\n",
    "    earnings = earnings[['Symbol','earnings_date','EPS Estimate','Reported EPS','Surprise(%)']]\n",
    "    \n",
    "    # 7. Save the earnings Data to a CSV file\n",
    "    earnings.to_csv(todirectory+ticker+'_earnings.csv', index=False)\n",
    "\n",
    "# 8. Test get_earnings()\n",
    "get_earnings('F')\n",
    "os.listdir(todirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HINT for # 5:\n",
    "\n",
    "The `Earnings Date` column is stored in the `earnings` DataFrame as a string object. You can use text splitting and the **datetime** function on that string to extract the date. To explain how to do this, let's start with a simple Python example.\n",
    "\n",
    "Suppose you have a string variable called `date`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = 'Oct 23, 2019, 4 AMEST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the date and store the variable as a **datetime** object, we can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_date = date.split(',')\n",
    "fixed_date = fixed_date[0]+','+fixed_date[1]\n",
    "fixed_date = dt.datetime.strptime(fixed_date, '%b %d, %Y')\n",
    "print(fixed_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the same type of analysis for a column in a pandas DataFrame, you can create a function that takes the `date` as in input and returns the newly-created **datetime** `date`. You can then apply that function to the appropriate column in the **pandas** DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date):\n",
    "    fixed_date = date.split(',')\n",
    "    fixed_date = fixed_date[0]+','+fixed_date[1]\n",
    "    fixed_date = dt.datetime.strptime(fixed_date, '%b %d, %Y')\n",
    "    return fixed_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings = pd.DataFrame({'ticker':['F', 'AAPL', 'WMT'], 'Earnings Date':['Oct 23, 2019, 4 AMEST', 'Dec 5, 2017, 6 AMEST', 'Jan 20, 2019, 9 PMEST']})\n",
    "earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings['earnings_date'] = earnings['Earnings Date'].apply(convert_date)\n",
    "earnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain S&P 500 Tickers from Wikipedia\n",
    "\n",
    "1. Use the **pandas read_html** function to read in this list of S&P 500 companies from Wikipedia: https://en.wikipedia.org/wiki/List_of_S%26P_500_companies.\n",
    "2. Create a DataFrame called `sp500`, keeping only the `Symbol` and `Security` columns.\n",
    "3. Keep only the first 10 rows in the `sp500` DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution - Obtain S&P 500 Tickers from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Read HTML\n",
    "html = requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies').text\n",
    "dfs = pd.read_html(html)\n",
    "df = dfs[0]\n",
    "\n",
    "# 2. Create a DataFrame called sp500\n",
    "sp500 = df.copy()\n",
    "\n",
    "# 3. Keep only the first 10 rows\n",
    "sp500 = sp500.head(10)\n",
    "\n",
    "# Print the first 10 rows\n",
    "sp500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through the First Ten Firms in the S&P 500 DataFrame to Obtain the Earnings and Price Tables for Each Ticker Symbol\n",
    "\n",
    "1. Use a **for** loop to loop through each row of the `sp500` DataFrame using the **iterrows** function. See the HINT below.\n",
    "2. For each `Symbol` (i.e., ticker), download the 'TICKER_earnings.csv' file to the \"Yahoo Finance Data\" folder using the `get_earnings` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution - Loop through the First Ten Firms in the S&P 500 DataFrame to Obtain the Earnings and Price Tables for Each Ticker Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in sp500.iterrows():\n",
    "    ticker = row['Symbol']\n",
    "    get_earnings(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HINT for # 2\n",
    "\n",
    "To loop through each row of a DataFrame called `sp500` and to extract the `Symbol` (i.e., ticker) from each row, you can use the following code:\n",
    "\n",
    "    for index,row in sp500.iterrows():\n",
    "        ticker = row['Symbol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Earnings Data\n",
    "\n",
    "1. Create an empty list called `all_data`. (i.e., `all_data = []`)\n",
    "2. Create a list of file names called `filenames` from the Yahoo Finance Data folder using `os.listdir(DIRECTORY)`.\n",
    "3. Use a **for** loop to loop through each file name in the `filenames` list and do the following:\n",
    "    1. If '_earnings' is in the filename, execute the next steps.\n",
    "    2. Extract the ticker from the filename using the **.split()** function.\n",
    "    3. Read the file into a **pandas** DataFrame called `data` using the **read_csv** function.\n",
    "    4. Add the ticker you extracted in Step B above to a new column called `ticker` in the `data` DataFrame.\n",
    "    5. Append the `data` DataFrame to the `all_data` list you created in Step 1 above using the **.append()** function.\n",
    "4. Create a DataFrame called `earnings` by concatenating the `all_data` list of DataFrames using the code: `earnings = pd.concat(all_data)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution - Combine Earnings Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create an empty list\n",
    "all_data = []\n",
    "\n",
    "# 2. Create a list\n",
    "filenames = os.listdir(todirectory)\n",
    "\n",
    "# 3. Loop\n",
    "for filename in filenames:\n",
    "    # A. Conditional Flow\n",
    "    if '_earnings' in filename:\n",
    "        \n",
    "        # B. Extract Ticker\n",
    "        ticker = filename.split('_')[0]\n",
    "        \n",
    "        # C. Read the file\n",
    "        data = pd.read_csv(todirectory+filename)\n",
    "        \n",
    "        # D. Add the ticker\n",
    "        data['ticker'] = ticker\n",
    "        \n",
    "        # Append\n",
    "        all_data.append(data)\n",
    "\n",
    "# Create a Dataframe and print its head\n",
    "earnings = pd.concat(all_data)\n",
    "earnings.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
