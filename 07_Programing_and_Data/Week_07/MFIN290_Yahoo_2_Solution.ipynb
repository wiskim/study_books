{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Yahoo! Finance with scrapy\n",
    "\n",
    "In this tutorial, we will use the **scrapy** module in Python to scrape data from *Yahoo! Finance*.\n",
    "\n",
    "We will illustrate using Ford's profile page on *Yahoo! Finance* ('https://finance.yahoo.com/quote/F/profile?p=F')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load HTML using the requests Module\n",
    "\n",
    "Before we use **scrapy** on our website, we must first load the HTML of the website into our Python program. We can do so using the **requests** module. Let's load Ford's Yahoo Finance website HTML into a variable called **html**:\n",
    "\n",
    "**UPDATE:** It seems that Yahoo! Finance has learned to recognize when their site is accessed by a bot such as in this code. However, I found a workaround. You can pass headers to your **requests.get** function to mimic a real browser. The code below shows an example of this. The *headers* variable contains a dictionary of potential \"user agents\" such as Mozilla, Chrome, etc. To use it in your **requests.get** function, simply add **headers=headers** as done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36' } \n",
    "html = requests.get('https://finance.yahoo.com/quote/F', headers=headers).text \n",
    "\n",
    "print(html[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use the **Selector** function within the **scrapy** module to read the HTML of our website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.selector import Selector\n",
    "\n",
    "response = Selector(text=html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as in our simple examples in the previous tutorial, we can now use **xpath** functions on the **response** variable to extract data from our website. For example, let's extract the title of our website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.xpath('//title/text()').extract_first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's say we want to extract the 'Market Cap' from the website. The simplest way to do so is to identify the xpath of the 'Market Cap' within our HTML. Thankfully, our web browser (e.g., Chrome) has a simple built-in way to identify the xpath of the objects that you see on the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mktcap = response.xpath('//*[@id=\"nimbus-app\"]/section/section/section/article/div[3]/ul/li[9]/span[2]/fin-streamer').extract_first()\n",
    "print(mktcap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract only the text and not the tags surrounding the text, we can modify the xpath as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mktcap = response.xpath('//*[@id=\"nimbus-app\"]/section/section/section/article/div[3]/ul/li[9]/span[2]/fin-streamer/text()').extract_first()\n",
    "print(mktcap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape Data for Multiple Companies\n",
    "\n",
    "Let's now create a simple function to obtain the market cap for any given ticker. Then we can use that function to obtain data for any given list of tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_mktcap(ticker):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36' } \n",
    "    html = requests.get('https://finance.yahoo.com/quote/'+ticker, headers=headers).text\n",
    "    response = Selector(text=html)\n",
    "    mktcap = response.xpath('//*[@id=\"nimbus-app\"]/section/section/section/article/div[3]/ul/li[9]/span[2]/fin-streamer/text()').extract_first()\n",
    "    return mktcap\n",
    "\n",
    "# List of tickers to obtain\n",
    "tickers = ['F','AAPL','MSFT','AMZN']\n",
    "\n",
    "# Initalize a new pandas DataFrame\n",
    "df = pd.DataFrame(columns = ['ticker','mktcap'])\n",
    "\n",
    "# Iterate through list of tickers and save mktcap to our df DataFrame\n",
    "for ticker in tickers:\n",
    "    mktcap = get_mktcap(ticker)\n",
    "    df = pd.concat([df, pd.DataFrame({'ticker': [ticker], 'mktcap': [mktcap]})], ignore_index=True)\n",
    "    \n",
    "# Print the df DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise -- Practice Using scrapy and xpath\n",
    "\n",
    "1. Obtain the 'Previous Close' for Ford listed on Ford's Yahoo! Finance Summary page.\n",
    "2. Obtain the '1y Target Est' for Ford listed on Ford's Yahoo! Finance Summary page.\n",
    "3. Create a function to obtain the previous closing price and one-year target estimate for the following tickers: 'AMZN', 'FB', 'V', 'HD', and 'KO'. Create a new pandas DataFrame with the following columns: **ticker**, **close**, **target_est** and add data for these companies to the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution for # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get('https://finance.yahoo.com/quote/F', headers=headers).text \n",
    "response = Selector(text=html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = response.xpath('//*[@id=\"nimbus-app\"]/section/section/section/article/div[3]/ul/li[1]/span[2]/fin-streamer/text()').extract_first()\n",
    "print(close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution for # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_est = response.xpath('//*[@id=\"nimbus-app\"]/section/section/section/article/div[3]/ul/li[16]/span[2]/fin-streamer/text()').extract_first()\n",
    "print(target_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution for # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ticker):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36' } \n",
    "    html = requests.get('https://finance.yahoo.com/quote/'+ticker, headers=headers).text\n",
    "    response = Selector(text=html)\n",
    "    close = response.xpath('//*[@id=\"nimbus-app\"]/section/section/section/article/div[3]/ul/li[1]/span[2]/fin-streamer/text()').extract_first()\n",
    "    target_est = response.xpath('//*[@id=\"nimbus-app\"]/section/section/section/article/div[3]/ul/li[16]/span[2]/fin-streamer/text()').extract_first()\n",
    "    return close,target_est\n",
    "\n",
    "# List of tickers to obtain\n",
    "tickers = ['AMZN','FB','V','HD','KO']\n",
    "\n",
    "# Initalize a new pandas DataFrame\n",
    "df = pd.DataFrame(columns = ['ticker','close','target_est'])\n",
    "\n",
    "# Iterate through list of tickers and save mktcap to our df DataFrame\n",
    "for ticker in tickers:\n",
    "    close,target_est = get_data(ticker)\n",
    "    df = pd.concat([df, pd.DataFrame({'ticker':[ticker], 'close':[close], 'target_est':[target_est]})], ignore_index=True)\n",
    "\n",
    "# Print the df DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
